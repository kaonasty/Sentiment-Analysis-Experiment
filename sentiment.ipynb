{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_preprocess.tsv', sep='\\t', header=None, names=['text','label'])\n",
    "valid_df = pd.read_csv('valid_preprocess.tsv', sep='\\t', header=None, names=['text','label'])\n",
    "test_df = pd.read_csv('test_preprocess.tsv', sep='\\t', header=None, names=['text','label'])\n",
    "test_masked_df = pd.read_csv('test_preprocess_masked_label.tsv', sep='\\t', header=None, names=['text','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pisahkan fitur dan label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = train_df['text']\n",
    "y_train = train_df['label']\n",
    "X_valid_text = valid_df['text']\n",
    "y_valid = valid_df['label']\n",
    "X_test_text = test_df['text']\n",
    "y_test_masked = test_masked_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fungsi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_valid, y_train, y_valid, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    print(f\"Evaluasi untuk {model_name}\")\n",
    "    print(classification_report(y_valid, y_pred))\n",
    "    print(f\"Accuracy: {accuracy_score(y_valid, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_valid, y_pred, average='weighted')}\")\n",
    "    print(f\"Recall: {recall_score(y_valid, y_pred, average='weighted')}\")\n",
    "    print(f\"F1-Score: {f1_score(y_valid, y_pred, average='weighted')}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Unigram Bag of Words----\n",
      "Evaluasi untuk Logistic Regression - Unigram\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.87      0.84       394\n",
      "     neutral       0.83      0.69      0.76       131\n",
      "    positive       0.92      0.91      0.91       735\n",
      "\n",
      "    accuracy                           0.87      1260\n",
      "   macro avg       0.85      0.83      0.84      1260\n",
      "weighted avg       0.88      0.87      0.87      1260\n",
      "\n",
      "Accuracy: 0.8746031746031746\n",
      "Precision: 0.875828414930559\n",
      "Recall: 0.8746031746031746\n",
      "F1-Score: 0.8741505866783319\n",
      "\n",
      "\n",
      "Evaluasi untuk Naive Bayes - Unigram\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.85      0.81       394\n",
      "     neutral       0.91      0.64      0.75       131\n",
      "    positive       0.90      0.90      0.90       735\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.86      0.80      0.82      1260\n",
      "weighted avg       0.86      0.86      0.86      1260\n",
      "\n",
      "Accuracy: 0.8563492063492063\n",
      "Precision: 0.8606630837226277\n",
      "Recall: 0.8563492063492063\n",
      "F1-Score: 0.8554702521138013\n",
      "\n",
      "\n",
      "Evaluasi untuk SVM - Unigram\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.86      0.82       394\n",
      "     neutral       0.78      0.68      0.73       131\n",
      "    positive       0.92      0.90      0.91       735\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.83      0.81      0.82      1260\n",
      "weighted avg       0.87      0.86      0.86      1260\n",
      "\n",
      "Accuracy: 0.8634920634920635\n",
      "Precision: 0.8655804604119415\n",
      "Recall: 0.8634920634920635\n",
      "F1-Score: 0.8635518429494502\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"----Unigram Bag of Words----\")\n",
    "vectorizer_unigram = CountVectorizer(ngram_range=(1, 1))  # Unigram model\n",
    "X_train_bow_unigram = vectorizer_unigram.fit_transform(X_train_text)\n",
    "X_valid_bow_unigram = vectorizer_unigram.transform(X_valid_text)\n",
    "# Train and evaluate models\n",
    "evaluate_model(LogisticRegression(), X_train_bow_unigram, X_valid_bow_unigram, y_train, y_valid, \"Logistic Regression - Unigram\")\n",
    "evaluate_model(MultinomialNB(), X_train_bow_unigram, X_valid_bow_unigram, y_train, y_valid, \"Naive Bayes - Unigram\")\n",
    "evaluate_model(SVC(), X_train_bow_unigram, X_valid_bow_unigram, y_train, y_valid, \"SVM - Unigram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Bigram Bag of Words----\n",
      "Evaluasi untuk Logistic Regression - Bigram\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.87       394\n",
      "     neutral       0.82      0.67      0.74       131\n",
      "    positive       0.93      0.93      0.93       735\n",
      "\n",
      "    accuracy                           0.89      1260\n",
      "   macro avg       0.87      0.83      0.85      1260\n",
      "weighted avg       0.89      0.89      0.89      1260\n",
      "\n",
      "Accuracy: 0.8928571428571429\n",
      "Precision: 0.8923324967857992\n",
      "Recall: 0.8928571428571429\n",
      "F1-Score: 0.8915856050526766\n",
      "\n",
      "\n",
      "Evaluasi untuk Naive Bayes - Bigram\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.80      0.78       394\n",
      "     neutral       0.96      0.38      0.55       131\n",
      "    positive       0.86      0.93      0.89       735\n",
      "\n",
      "    accuracy                           0.83      1260\n",
      "   macro avg       0.86      0.70      0.74      1260\n",
      "weighted avg       0.84      0.83      0.82      1260\n",
      "\n",
      "Accuracy: 0.8317460317460318\n",
      "Precision: 0.8401066900359865\n",
      "Recall: 0.8317460317460318\n",
      "F1-Score: 0.8220323580839388\n",
      "\n",
      "\n",
      "Evaluasi untuk SVM - Bigram\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.88      0.81       394\n",
      "     neutral       0.87      0.66      0.75       131\n",
      "    positive       0.93      0.89      0.91       735\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.85      0.81      0.82      1260\n",
      "weighted avg       0.87      0.86      0.86      1260\n",
      "\n",
      "Accuracy: 0.861904761904762\n",
      "Precision: 0.8689668608078984\n",
      "Recall: 0.861904761904762\n",
      "F1-Score: 0.8622536483798834\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Bigram Bag of Words\n",
    "print(\"----Bigram Bag of Words----\")\n",
    "vectorizer_bigram = CountVectorizer(ngram_range=(1, 2))  # Bigram model\n",
    "X_train_bow_bigram = vectorizer_bigram.fit_transform(X_train_text)\n",
    "X_valid_bow_bigram = vectorizer_bigram.transform(X_valid_text)\n",
    "\n",
    "# Train and evaluate models\n",
    "evaluate_model(LogisticRegression(), X_train_bow_bigram, X_valid_bow_bigram, y_train, y_valid, \"Logistic Regression - Bigram\")\n",
    "evaluate_model(MultinomialNB(), X_train_bow_bigram, X_valid_bow_bigram, y_train, y_valid, \"Naive Bayes - Bigram\")\n",
    "evaluate_model(SVC(), X_train_bow_bigram, X_valid_bow_bigram, y_train, y_valid, \"SVM - Bigram\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----TF-IDF Bag of Words----\n",
      "Evaluasi untuk Logistic Regression - TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.83       394\n",
      "     neutral       0.88      0.66      0.76       131\n",
      "    positive       0.91      0.92      0.92       735\n",
      "\n",
      "    accuracy                           0.87      1260\n",
      "   macro avg       0.87      0.81      0.84      1260\n",
      "weighted avg       0.88      0.87      0.87      1260\n",
      "\n",
      "Accuracy: 0.8746031746031746\n",
      "Precision: 0.8751984219727619\n",
      "Recall: 0.8746031746031746\n",
      "F1-Score: 0.8731706074320327\n",
      "\n",
      "\n",
      "Evaluasi untuk Naive Bayes - TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.73      0.75       394\n",
      "     neutral       1.00      0.23      0.37       131\n",
      "    positive       0.82      0.96      0.88       735\n",
      "\n",
      "    accuracy                           0.81      1260\n",
      "   macro avg       0.86      0.64      0.67      1260\n",
      "weighted avg       0.82      0.81      0.79      1260\n",
      "\n",
      "Accuracy: 0.8095238095238095\n",
      "Precision: 0.8229169569611013\n",
      "Recall: 0.8095238095238095\n",
      "F1-Score: 0.7881002717216103\n",
      "\n",
      "\n",
      "Evaluasi untuk SVM - TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.88      0.84       394\n",
      "     neutral       0.88      0.66      0.76       131\n",
      "    positive       0.93      0.92      0.92       735\n",
      "\n",
      "    accuracy                           0.88      1260\n",
      "   macro avg       0.87      0.82      0.84      1260\n",
      "weighted avg       0.88      0.88      0.88      1260\n",
      "\n",
      "Accuracy: 0.8793650793650793\n",
      "Precision: 0.8820221744297958\n",
      "Recall: 0.8793650793650793\n",
      "F1-Score: 0.8785438587826807\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. TF-IDF Bag of Words\n",
    "print(\"----TF-IDF Bag of Words----\")\n",
    "vectorizer_tfidf = TfidfVectorizer(ngram_range=(1, 1))  # Unigram model with TF-IDF weighting\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train_text)\n",
    "X_valid_tfidf = vectorizer_tfidf.transform(X_valid_text)\n",
    "\n",
    "# Train and evaluate models\n",
    "evaluate_model(LogisticRegression(), X_train_tfidf, X_valid_tfidf, y_train, y_valid, \"Logistic Regression - TF-IDF\")\n",
    "evaluate_model(MultinomialNB(), X_train_tfidf, X_valid_tfidf, y_train, y_valid, \"Naive Bayes - TF-IDF\")\n",
    "evaluate_model(SVC(), X_train_tfidf, X_valid_tfidf, y_train, y_valid, \"SVM - TF-IDF\")\n"
   ]
  },
{
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Evaluation on Test Masked Data----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         0\n",
      "     neutral       1.00      0.10      0.18       500\n",
      "    positive       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.10       500\n",
      "   macro avg       0.33      0.03      0.06       500\n",
      "weighted avg       1.00      0.10      0.18       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco langi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\marco langi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\marco langi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Additional: Evaluation on the masked test set\n",
    "print(\"----Evaluation on Test Masked Data----\")\n",
    "X_test_bow_unigram = vectorizer_unigram.transform(X_test_text)  # Unigram feature transformation for test set\n",
    "model = LogisticRegression()  # Replace with the model you want to use\n",
    "model.fit(X_train_bow_unigram, y_train)\n",
    "y_pred_test = model.predict(X_test_bow_unigram)\n",
    "print(classification_report(y_test_masked, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
